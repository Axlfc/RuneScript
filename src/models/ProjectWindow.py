import json
import os
import logging
import random
import re
import subprocess
import threading
import queue
import tkinter as tk
import uuid
from tkinter import ttk, messagebox, filedialog, scrolledtext
from typing import Dict, Optional, Any, List, Callable, Union
from datetime import datetime


class AIResponseParser:
    @staticmethod
    def validate_prompt(prompt):
        """
        Validate the project generation prompt.

        :param prompt: User-provided project description
        :return: Boolean indicating prompt validity
        """
        return prompt and len(prompt.split()) >= 3

    @staticmethod
    def parse_ai_response(ai_response):
        """
        Parse the AI-generated project metadata.

        :param ai_response: JSON or structured response from AI
        :return: Parsed project metadata dictionary
        """
        try:
            # If AI response is a JSON string, parse it
            if isinstance(ai_response, str):
                parsed_data = json.loads(ai_response)
            else:
                parsed_data = ai_response

            # Ensure all required fields are present with default values
            metadata = {
                'project_name': parsed_data.get('project_name', 'Unnamed Project'),
                'project_description': parsed_data.get('project_description', 'No description provided'),
                'project_structure': parsed_data.get('project_structure', []),
                'key_features': parsed_data.get('key_features', []),
                'project_tasks': parsed_data.get('project_tasks', []),
                'implemented_features': parsed_data.get('implemented_features', []),
                'planned_features': parsed_data.get('planned_features', []),
                'feature_priorities': parsed_data.get('feature_priorities', {
                    'high': [],
                    'medium': [],
                    'low': []
                }),
                'validation_notes': parsed_data.get('validation_notes', [])
            }

            return metadata

        except (json.JSONDecodeError, TypeError) as e:
            logging.error(f"Error parsing AI response: {e}")
            return {
                'project_name': 'Error Project',
                'project_description': 'Failed to parse AI response',
                'project_structure': [],
                'key_features': [],
                'project_tasks': ['Resolve AI response parsing error'],
                'implemented_features': [],
                'planned_features': [],
                'feature_priorities': {},
                'validation_notes': [str(e)]
            }


class ProjectManager:
    @staticmethod
    def create_project_structure(project_path: str, metadata: Dict[str, Any], logger: Callable[[str], None]):
        """
        Create the project structure, generate files, and log progress.
        Enhanced with more robust error handling and flexibility.
        """
        try:
            logger("Creating project structure...")

            # Ensure project path exists
            os.makedirs(project_path, exist_ok=True)

            # Create directories with error handling
            directories = ['src', 'tests', 'docs', 'config', 'scripts']
            directories.extend(metadata.get('project_structure', []))

            for directory in directories:
                try:
                    dir_path = os.path.join(project_path, directory)
                    os.makedirs(dir_path, exist_ok=True)
                    logger(f"Created directory: {dir_path}")
                except OSError as dir_error:
                    logger(f"Warning: Could not create directory {directory}: {dir_error}")

            # Create files with more robust handling
            initial_files = metadata.get('initial_files', {})
            for filename, content in initial_files.items():
                try:
                    file_path = os.path.join(project_path, filename)
                    os.makedirs(os.path.dirname(file_path), exist_ok=True)
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(content or '')
                    logger(f"Created file: {file_path}")
                except IOError as file_error:
                    logger(f"Error creating file {filename}: {file_error}")

            # Write README with fallback
            readme_path = os.path.join(project_path, 'README.md')
            try:
                with open(readme_path, 'w', encoding='utf-8') as readme:
                    readme.write(metadata.get('readme', '# Project Generated by Red-Green-Refactor IDE'))
                logger(f"Created README: {readme_path}")
            except IOError as readme_error:
                logger(f"Could not create README: {readme_error}")

        except Exception as e:
            logger(f"Critical error in project structure creation: {e}")
            raise

    @staticmethod
    def write_todo_list(project_path: str, tasks: Union[List[str], List[Dict[str, str]]],
                        logger: Callable[[str], None]):
        """
        Write a TODO.md file to track tasks with enhanced flexibility.

        Supports both list of strings and list of dictionaries with 'description' key.
        """
        todo_path = os.path.join(project_path, 'TODO.md')
        try:
            with open(todo_path, 'w', encoding='utf-8') as todo_file:
                todo_file.write("# TODO List\n\n")

                # Handle different task input formats
                for task in tasks:
                    # If task is a dictionary, try to get 'description'
                    if isinstance(task, dict):
                        description = task.get('description', str(task))
                    # If task is a string, use it directly
                    elif isinstance(task, str):
                        description = task
                    # For other types, convert to string
                    else:
                        description = str(task)

                    # Write task with checkbox
                    todo_file.write(f"- [ ] {description}\n")

            logger("Wrote TODO.md with tasks.")
        except IOError as e:
            logger(f"Error writing TODO list: {e}")

    @staticmethod
    def write_list_md(project_path: str, features: Dict[str, List[str]], logger: Callable[[str], None]):
        """
        Write a LIST.md file to track features and priorities with improved error handling.
        """
        list_path = os.path.join(project_path, 'LIST.md')
        try:
            with open(list_path, 'w', encoding='utf-8') as list_file:
                list_file.write("# Feature Tracking\n\n")

                # Ensure default structure if features are empty
                if not features:
                    features = {
                        'high': ['Initial project setup'],
                        'medium': [],
                        'low': []
                    }

                for priority, feature_list in features.items():
                    # Normalize priority display
                    display_priority = priority.capitalize()
                    list_file.write(f"## {display_priority} Priority\n")

                    # Handle empty feature lists
                    if not feature_list:
                        list_file.write("- No features defined\n")
                    else:
                        for feature in feature_list:
                            list_file.write(f"- {feature}\n")

                    list_file.write("\n")

            logger("Wrote LIST.md with feature tracking.")
        except IOError as e:
            logger(f"Error writing feature list: {e}")

    @staticmethod
    def run_tests(project_path: str, logger: Callable[[str], None]) -> bool:
        """
        Run tests in the project with enhanced logging and error handling.
        """
        logger("Running tests...")
        try:
            # Use pytest with comprehensive reporting
            result = subprocess.run(
                [
                    'pytest',
                    '--disable-warnings',
                    '--maxfail=1',
                    '-v',  # Verbose output
                    '--tb=short'  # Shorter traceback
                ],
                cwd=project_path,
                text=True,
                capture_output=True
            )

            # Log full output
            logger(result.stdout)

            # Log errors separately
            if result.stderr:
                logger(f"Test Stderr: {result.stderr}")

            # Determine test success
            test_success = result.returncode == 0

            # Provide detailed logging
            if test_success:
                logger("All tests passed successfully!")
            else:
                logger("Some tests failed. Review the output above.")

            return test_success

        except Exception as e:
            logger(f"Critical error running tests: {e}")
            return False


class AutonomousProjectAgent:
    def __init__(self, project_path: str):
        """
        Initialize the Autonomous Project Agent for managing project development.

        :param project_path: Base directory for the project
        """
        self.project_path = project_path

        # Queues for managing asynchronous tasks
        self.task_queue = queue.Queue()
        self.result_queue = queue.Queue()

        # Project development state tracking
        self.current_phase = "idle"
        self.development_stages = [
            "requirement_analysis",
            "architecture_design",
            "test_driven_development",
            "implementation",
            "refactoring",
            "validation"
        ]

        # Logging setup
        self.setup_logging()

    def setup_logging(self):
        """Configure logging for the autonomous project agent."""
        log_file = os.path.join(self.project_path, 'autonomous_agent.log')
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s [AutonomousProjectAgent] %(levelname)s: %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )

    def process_prompt_with_ai(self, stage: str, context: Dict) -> Optional[str]:
        """
        Process AI prompt for a specific development stage.
        """
        try:
            combined_input = json.dumps({"stage": stage, "context": context})
            ai_script_path = "src/models/ai_assistant.py"
            command = ["python", ai_script_path, combined_input]

            process = subprocess.Popen(
                command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                encoding='utf-8'
            )

            ai_response, error = process.communicate()
            if error or process.returncode != 0:
                logging.error(f"AI Assistant Error: {error}")
                return None

            return ai_response.strip()

        except Exception as e:
            logging.error(f"Error processing AI prompt: {e}")
            return None

    def start_autonomous_development(self, initial_requirements: str):
        """
        Initiate the autonomous project development process.

        :param initial_requirements: Initial project requirements or description
        """
        threading.Thread(
            target=self._development_workflow,
            args=(initial_requirements,),
            daemon=True
        ).start()

    def _development_workflow(self, initial_requirements: str):
        """
        Core development workflow orchestrating project creation.

        :param initial_requirements: Initial project requirements or description
        """
        try:
            # Phase 1: Requirement Analysis
            self.current_phase = "requirement_analysis"
            project_scope = self._analyze_requirements(initial_requirements)

            # Phase 2: Architecture Design
            self.current_phase = "architecture_design"
            project_architecture = self._design_project_architecture(project_scope)

            # Phase 3: Test-Driven Development
            self.current_phase = "test_driven_development"
            initial_tests = self._generate_initial_tests(project_architecture)

            # Phase 4: Implementation
            self.current_phase = "implementation"
            implementation_results = self._implement_features(initial_tests)

            # Phase 5: Refactoring
            self.current_phase = "refactoring"
            self._perform_code_refactoring(implementation_results)

            # Phase 6: Validation
            self.current_phase = "validation"
            validation_results = self._validate_project()

            self.current_phase = "completed"
            logging.info(f"Autonomous project development completed: {validation_results}")

        except Exception as e:
            logging.error(f"Autonomous development failed: {e}")
            self.current_phase = "error"

    def _analyze_requirements(self, requirements: str) -> Dict:
        """
        Analyze and break down project requirements.

        :param requirements: Initial project description
        :return: Structured project scope
        """
        logging.info(f"Analyzing requirements: {requirements}")

        context = {
            "requirements": requirements,
            "project_name": self._generate_project_name()
        }

        ai_response = self.process_prompt_with_ai("requirement_analysis", context)

        # Parse AI response or use default
        try:
            project_scope = json.loads(ai_response) if ai_response else {
                "project_name": context["project_name"],
                "key_features": ["Core Functionality"],
                "constraints": []
            }
        except json.JSONDecodeError:
            project_scope = {
                "project_name": context["project_name"],
                "key_features": ["Core Functionality"],
                "constraints": []
            }

        return project_scope

    def _design_project_architecture(self, project_scope: Dict) -> Dict:
        """
        Design initial project architecture and structure.

        :param project_scope: Analyzed project requirements
        :return: Project architecture blueprint
        """
        logging.info("Designing project architecture")

        context = {
            "project_scope": project_scope,
            "default_structure": [
                "src/",
                "tests/",
                "docs/",
                "README.md"
            ]
        }

        ai_response = self.process_prompt_with_ai("architecture_design", context)

        # Parse AI response or use default
        try:
            architecture = json.loads(ai_response) if ai_response else {
                "project_name": project_scope.get("project_name", "Unnamed Project"),
                "directory_structure": context["default_structure"],
                "initial_modules": [],
                "testing_framework": "pytest"
            }
        except json.JSONDecodeError:
            architecture = {
                "project_name": project_scope.get("project_name", "Unnamed Project"),
                "directory_structure": context["default_structure"],
                "initial_modules": [],
                "testing_framework": "pytest"
            }

        return architecture

    def _generate_initial_tests(self, architecture: Dict) -> List[Dict]:
        """
        Generate initial test cases for the project.

        :param architecture: Project architecture blueprint
        :return: List of initial test cases
        """
        logging.info("Generating initial test cases")

        context = {
            "architecture": architecture
        }

        ai_response = self.process_prompt_with_ai("test_generation", context)

        # Parse AI response or use default
        try:
            initial_tests = json.loads(ai_response) if ai_response else [
                {
                    "name": "test_project_initialization",
                    "description": "Verify project initializes correctly",
                    "module": "test_core.py"
                }
            ]
        except json.JSONDecodeError:
            initial_tests = [
                {
                    "name": "test_project_initialization",
                    "description": "Verify project initializes correctly",
                    "module": "test_core.py"
                }
            ]

        return initial_tests

    def _implement_features(self, tests: List[Dict]) -> Dict:
        """
        Implement features based on generated test cases.

        :param tests: List of test cases
        :return: Implementation results
        """
        logging.info("Implementing features")

        context = {
            "tests": tests
        }

        ai_response = self.process_prompt_with_ai("feature_implementation", context)

        # Parse AI response or use default
        try:
            implementation_results = json.loads(ai_response) if ai_response else {
                "implemented_modules": [],
                "test_coverage": {}
            }
        except json.JSONDecodeError:
            implementation_results = {
                "implemented_modules": [],
                "test_coverage": {}
            }

        return implementation_results

    def _perform_code_refactoring(self, implementation_results: Dict):
        """
        Refactor implemented code to improve quality and maintainability.

        :param implementation_results: Results from feature implementation
        """
        logging.info("Performing code refactoring")

        context = {
            "implementation_results": implementation_results
        }

        self.process_prompt_with_ai("code_refactoring", context)

    def _validate_project(self) -> Dict:
        """
        Validate the overall project quality and completeness.

        :return: Validation results
        """
        logging.info("Validating project")

        validation_results = {
            "test_success_rate": self._run_tests(),
            "code_quality_score": self._analyze_code_quality()
        }

        return validation_results

    def _run_tests(self) -> float:
        """
        Run project tests and calculate success rate.

        :return: Percentage of tests passed
        """
        try:
            result = subprocess.run(
                ['pytest', '--disable-warnings', '--quiet'],
                capture_output=True,
                text=True,
                cwd=self.project_path
            )

            # Basic test success rate calculation
            total_tests = result.stdout.count('collected')
            passed_tests = result.stdout.count('passed')

            success_rate = (passed_tests / total_tests) * 100 if total_tests > 0 else 0
            return success_rate

        except Exception as e:
            logging.error(f"Test execution failed: {e}")
            return 0.0

    def _analyze_code_quality(self) -> float:
        """
        Perform basic code quality analysis.

        :return: Code quality score (0-100)
        """
        try:
            result = subprocess.run(
                ['pylint', self.project_path],
                capture_output=True,
                text=True
            )

            # Parse pylint output and convert to quality score
            # This is a simplistic implementation and can be enhanced
            quality_score = 100 - result.stdout.count('issue')
            return max(0, min(quality_score, 100))

        except Exception as e:
            logging.error(f"Code quality analysis failed: {e}")
            return 50.0  # Default neutral score

    def _generate_project_name(self) -> str:
        """
        Generate a unique project name.

        :return: Generated project name
        """
        project_prefixes = [
            "quantum", "dynamic", "smart", "advanced", "intelligent",
            "adaptive", "innovative", "next-gen", "ultra", "pro"
        ]
        project_suffixes = [
            "system", "framework", "solution", "engine", "platform"
        ]

        prefix = random.choice(project_prefixes)
        suffix = random.choice(project_suffixes)
        unique_id = str(uuid.uuid4())[:8]

        return f"{prefix}_{suffix}_{unique_id}"

    def get_current_status(self) -> Dict:
        """
        Retrieve the current status of the autonomous project development.

        :return: Current development status
        """
        return {
            "phase": self.current_phase,
            "timestamp": datetime.now().isoformat()
        }


class ProjectContext:
    def __init__(self, project_name, description, path):
        self.project_name = project_name
        self.description = description
        self.path = path
        self.milestones = []
        self.tasks = []
        self.completed_tasks = []
        self.documentation = []
        self.current_phase = "Planning"

    def update_milestones(self, milestone):
        if milestone not in self.milestones:
            self.milestones.append(milestone)

    def complete_task(self, task):
        if task in self.tasks:
            self.tasks.remove(task)
            self.completed_tasks.append(task)

    def add_documentation(self, doc):
        self.documentation.append(doc)


def generate_readme(context: ProjectContext):
    """
    Generate a README.md file with project information and instructions.
    """
    readme_path = os.path.join(context.path, 'README.md')
    with open(readme_path, 'w', encoding='utf-8') as readme:
        readme.write(f"# {context.project_name}\n\n")
        readme.write(f"## Description\n{context.description}\n\n")
        readme.write("## Milestones\n")
        for milestone in context.milestones:
            readme.write(f"- {milestone}\n")
        readme.write("\n## Completed Tasks\n")
        for task in context.completed_tasks:
            readme.write(f"- {task}\n")
        readme.write("\n## How to Use\n")
        readme.write("1. Follow the setup instructions in `docs/SETUP.md`.\n")
        readme.write("2. Run the main script in the `src` folder.\n")
        readme.write("3. Run tests using `pytest`.\n")



def transition_to_next_phase(context: ProjectContext):
    """
    Transition the project to the next phase based on context and progress.
    """
    if context.current_phase == "Planning":
        context.current_phase = "Development"
    elif context.current_phase == "Development":
        if len(context.tasks) == 0:
            context.current_phase = "Testing"
        else:
            logging.info("Development phase ongoing, tasks remain.")
    elif context.current_phase == "Testing":
        if all(task in context.completed_tasks for task in context.tasks):
            context.current_phase = "Documentation"
        else:
            logging.info("Testing phase ongoing, not all tasks completed.")
    elif context.current_phase == "Documentation":
        context.current_phase = "Ready for Review"
    else:
        logging.info("Project is ready for review.")



class RedGreenRefactorIDE:
    def __init__(self, root=None):
        self.root = root or tk.Tk()
        self.root.title("Red-Green-Refactor IDE")
        self.root.geometry("1400x900")

        self.ai_task_queue = queue.Queue()
        self.ai_response_queue = queue.Queue()
        self.setup_logging()
        self.setup_menu()
        self.create_main_layout()
        self.poll_queue()  # Start polling the queue
        self.projects_base_dir = os.path.join('data', 'projects')
        self.current_project_files = {}
        os.makedirs(self.projects_base_dir, exist_ok=True)

        self.current_project = None
        self.project_tree = None

        self.setup_logging()
        self.setup_ui()

    def setup_ui(self):
        menubar = tk.Menu(self.root)
        self.root.config(menu=menubar)

        file_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="File", menu=file_menu)
        file_menu.add_command(label="New Project", command=self.new_project)
        file_menu.add_command(label="Open Project", command=self.open_project)
        file_menu.add_separator()
        file_menu.add_command(label="Exit", command=self.root.quit)

        main_container = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
        main_container.pack(fill=tk.BOTH, expand=True)

        left_panel = ttk.Frame(main_container)
        self.project_tree = ttk.Treeview(left_panel, columns=('path',), show='tree')
        self.project_tree.pack(fill=tk.BOTH, expand=True)
        main_container.add(left_panel)

        right_panel = ttk.Frame(main_container)
        self.output_console = scrolledtext.ScrolledText(right_panel, wrap=tk.WORD, state='disabled', height=20)
        self.output_console.pack(fill=tk.BOTH, expand=True)
        main_container.add(right_panel)

    def poll_queue(self):
        """
        Process AI responses from the queue on the main thread.
        """
        try:
            while not self.ai_response_queue.empty():
                status, data = self.ai_response_queue.get_nowait()
                if status == "success":
                    self.finalize_project_generation(data)
                elif status == "error":
                    self.handle_generation_failure(error_message=data)
        except queue.Empty:
            pass
        finally:
            self.root.after(100, self.poll_queue)  # Poll the queue every 100ms

    def setup_menu(self):
        menubar = tk.Menu(self.root)
        self.root.config(menu=menubar)

        # Existing menu setup with additional error handling
        file_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="File", menu=file_menu)
        file_menu.add_command(label="New Project", command=self.safe_new_project)
        file_menu.add_command(label="Open Project", command=self.safe_open_project)
        file_menu.add_separator()
        file_menu.add_command(label="Exit", command=self.root.quit)

    def safe_new_project(self):
        try:
            self.new_project()
        except Exception as e:
            messagebox.showerror("Project Creation Error", str(e))
            logging.error(f"Project creation failed: {e}")

    def safe_open_project(self):
        try:
            self.open_project()
        except Exception as e:
            messagebox.showerror("Project Open Error", str(e))
            logging.error(f"Project open failed: {e}")

    def create_main_layout(self):
        # Existing main layout with enhanced error handling
        try:
            main_container = ttk.PanedWindow(self.root, orient=tk.HORIZONTAL)
            main_container.pack(fill=tk.BOTH, expand=True)

            # Layout components with extensive error handling
            left_panel = self.create_left_panel(main_container)
            right_panel = self.create_right_panel(main_container)

            main_container.add(left_panel)
            main_container.add(right_panel)

            self.create_command_bar(self.root)
        except Exception as e:
            messagebox.showerror("Layout Initialization Error", str(e))
            logging.critical(f"Layout creation failed: {e}")

    def create_left_panel(self, parent):
        left_panel = ttk.Frame(parent)
        self.project_tree = self.create_project_tree(left_panel)
        self.output_console = self.create_output_console(left_panel)
        return left_panel

    def create_right_panel(self, parent):
        right_panel = ttk.PanedWindow(parent, orient=tk.VERTICAL)
        self.ai_plan_listbox = self.create_ai_plan(right_panel)
        self.file_editor = self.create_file_editor(right_panel)
        return right_panel

    def create_project_tree(self, parent):
        tree = ttk.Treeview(parent, columns=('path',), show='tree')
        tree.pack(fill=tk.BOTH, expand=True)
        tree.bind('<<TreeviewSelect>>', self.on_file_select)
        return tree

    def create_output_console(self, parent):
        console = scrolledtext.ScrolledText(
            parent, height=15, wrap=tk.WORD, state='disabled'
        )
        console.pack(fill=tk.X, side=tk.BOTTOM)
        return console

    def create_ai_plan(self, parent):
        plan_frame = ttk.LabelFrame(parent, text="AI Project Plan")
        listbox = tk.Listbox(plan_frame, height=10)
        listbox.pack(fill=tk.BOTH, expand=True)
        parent.add(plan_frame)
        return listbox

    def create_file_editor(self, parent):
        editor_frame = ttk.LabelFrame(parent, text="File Contents")
        editor = scrolledtext.ScrolledText(
            editor_frame, wrap=tk.WORD, undo=True
        )
        editor.pack(fill=tk.BOTH, expand=True)
        editor.bind('<<Modified>>', self.on_file_modified)
        parent.add(editor_frame)
        return editor

    def create_command_bar(self, parent):
        command_bar = ttk.Frame(parent)
        command_bar.pack(fill=tk.X, padx=5, pady=5)

        ttk.Label(command_bar, text="Project Prompt:").pack(side=tk.LEFT, padx=(0, 5))
        self.prompt_entry = ttk.Entry(command_bar, width=50)
        self.prompt_entry.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5)

        button_frame = ttk.Frame(command_bar)
        button_frame.pack(side=tk.LEFT, padx=5)

        self.generate_btn = ttk.Button(
            button_frame, text="Generate Project", command=self.generate_project_with_ai
        )
        self.generate_btn.pack(side=tk.LEFT, padx=2)

        self.pause_btn = ttk.Button(
            button_frame, text="Pause", command=self.pause_project, state=tk.DISABLED
        )
        self.pause_btn.pack(side=tk.LEFT, padx=2)

        self.stop_btn = ttk.Button(
            button_frame, text="Stop", command=self.stop_project, state=tk.DISABLED
        )
        self.stop_btn.pack(side=tk.LEFT, padx=2)

    def process_prompt_with_ai(self, combined_input: str) -> Optional[str]:
        ai_script_path = "src/models/ai_assistant.py"
        python_executable = 'python'

        try:
            command = [python_executable, ai_script_path, combined_input]
            process = subprocess.Popen(
                command,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                encoding='utf-8'
            )
            ai_response, error = process.communicate()
            if process.returncode != 0 or error:
                raise Exception(f"AI Assistant Error: {error.strip()}")
            return ai_response.strip()
        except Exception as e:
            self.log_output(f"Failed to communicate with AI: {e}")
            return None

    def new_project(self):
        project_id = str(uuid.uuid4())
        project_path = os.path.join(self.projects_base_dir, project_id)
        os.makedirs(project_path, exist_ok=True)
        self.current_project = project_path
        self.log_output(f"New project created: {project_path}")

    def open_project(self):
        project_path = filedialog.askdirectory(initialdir=self.projects_base_dir)
        if project_path:
            self.current_project = project_path
            self.log_output(f"Opened project: {project_path}")
            self.populate_tree_view()

    def populate_tree_view(self):
        if not self.current_project:
            return

        self.project_tree.delete(*self.project_tree.get_children())
        for root, dirs, files in os.walk(self.current_project):
            parent = self.project_tree.insert('', 'end', text=os.path.basename(root), values=(root,))
            for file in files:
                self.project_tree.insert(parent, 'end', text=file, values=(os.path.join(root, file),))

    def run_project_generation(self, metadata: Dict[str, Any]):
        """
        Run project generation and ensure tasks are processed.
        """
        if not self.current_project:
            self.log_output("No project selected. Create or open a project first.")
            return

        self.log_output("Starting project generation...")

        # Initialize project context
        context = ProjectContext(
            project_name=metadata.get("project_name", "Unnamed Project"),
            description=metadata.get("project_description", "No description provided."),
            path=self.current_project
        )

        # Update milestones and tasks
        context.milestones.extend(metadata.get("milestones", []))
        context.tasks.extend(metadata.get("tasks", []))

        # Generate project structure
        ProjectManager.create_project_structure(self.current_project, metadata, self.log_output)

        # Write TODO.md
        ProjectManager.write_todo_list(self.current_project, context.tasks, self.log_output)

        # Generate documentation
        generate_readme(context)

        # Run tests
        if ProjectManager.run_tests(self.current_project, self.log_output):
            context.complete_task("Run all tests")
            self.log_output("All tests passed successfully!")

        # Update project phase
        transition_to_next_phase(context)

        if context.current_phase == "Ready for Review":
            self.log_output("Project development is complete and ready for review.")
        else:
            # Continue autonomous workflow
            self.continue_autonomous_workflow(metadata)

    def continue_autonomous_workflow(self, metadata: Dict[str, Any]):
        """
        Continue the workflow based on AI feedback and project state.
        """
        if not metadata.get("next_steps"):
            self.log_output("Project development is complete.")
            return

        self.log_output("Requesting additional steps from AI...")
        ai_agent = AutonomousProjectAgent(self.current_project)
        ai_feedback = ai_agent.process_prompt_with_ai("next_steps", {"current_state": metadata})

        if ai_feedback:
            parsed_metadata = AIResponseParser.parse_ai_response(ai_feedback)
            self.run_project_generation(parsed_metadata)
        else:
            self.log_output("No further steps provided by AI.")

    def generate_project_with_ai(self):
        """
        Start autonomous project generation with AI.
        """
        prompt = self.prompt_entry.get().strip()

        if not AIResponseParser.validate_prompt(prompt):
            messagebox.showwarning("Invalid Prompt", "Please provide a clear, meaningful project description.")
            return

        self.log_output("Starting AI-based autonomous project generation...")
        self.toggle_generation_ui(False)

        # Create project directory
        project_id = str(uuid.uuid4())
        project_path = os.path.join(self.projects_base_dir, project_id)
        os.makedirs(project_path, exist_ok=True)
        self.current_project = project_path

        # Initialize Autonomous Project Agent
        ai_agent = AutonomousProjectAgent(self.current_project)
        ai_response = ai_agent.process_prompt_with_ai("initial_project_setup", {"prompt": prompt})

        if ai_response:
            parsed_metadata = AIResponseParser.parse_ai_response(ai_response)
            self.run_project_generation(parsed_metadata)
        else:
            self.log_output("Failed to initialize the project with AI.")
            self.toggle_generation_ui(True)

    def threaded_ai_generation(self, prompt):
        """
        Run AI generation logic in a separate thread and enqueue results.
        """
        try:
            ai_response = self.process_prompt_with_ai(prompt)
            if ai_response:
                parsed_metadata = AIResponseParser.parse_ai_response(ai_response)
                self.ai_response_queue.put(("success", parsed_metadata))
            else:
                self.ai_response_queue.put(("error", "AI response is empty."))
        except Exception as e:
            logging.error(f"AI generation thread error: {e}")
            self.ai_response_queue.put(("error", str(e)))

    def finalize_project_generation(self, parsed_metadata):
        """
        Finalize the project generation with enhanced documentation and structure.

        :param parsed_metadata: Metadata returned by AI project generation
        """
        try:
            # Generate a sanitized project ID
            project_id = str(uuid.uuid4()).replace("-", "")
            project_path = os.path.normpath(os.path.join(self.projects_base_dir, project_id))

            # Create the project structure
            ProjectManager.create_project_structure(project_path, parsed_metadata)

            # Generate comprehensive project documentation
            self._generate_project_docs(project_path, parsed_metadata)

            # Set the current project and refresh the UI
            self.current_project = project_path
            self.populate_project_tree()

            # Format project structure and tasks for AI Plan
            project_structure = parsed_metadata.get('project_structure', [])
            project_tasks = parsed_metadata.get('project_tasks', [])

            # Update AI Plan with tasks
            formatted_tasks = '\n'.join(project_tasks)
            self.update_ai_plan(formatted_tasks)

            self.log_output(f"Project {project_id} generated successfully at {project_path}!")

        except Exception as e:
            logging.error(f"Project finalization error: {e}")
            messagebox.showerror("Generation Error", str(e))
        finally:
            self.toggle_generation_ui(True)

    def _generate_project_docs(self, project_path, parsed_metadata):
        """
        Generate comprehensive project documentation.

        :param project_path: Path to the project directory
        :param parsed_metadata: Metadata returned by AI project generation
        """
        # Ensure docs directory exists
        docs_dir = os.path.join(project_path, 'docs')
        os.makedirs(docs_dir, exist_ok=True)

        # Generate README.md
        readme_path = os.path.join(project_path, 'README.md')
        with open(readme_path, 'w') as f:
            f.write(f"# {parsed_metadata.get('project_name', 'Unnamed Project')}\n\n")
            f.write("## Project Overview\n")
            f.write(parsed_metadata.get('project_description', 'No description available') + "\n\n")
            f.write("## Key Features\n")
            for feature in parsed_metadata.get('key_features', []):
                f.write(f"- {feature}\n")
            f.write("\n## Setup and Installation\n")
            f.write("(Add setup instructions here)\n")

        # Generate TODO.md with project tasks
        todo_path = os.path.join(project_path, 'TODO.md')
        with open(todo_path, 'w') as f:
            f.write("# Project Tasks and Milestones\n\n")
            f.write("## Pending Tasks\n")
            for task in parsed_metadata.get('project_tasks', []):
                f.write(f"- [ ] {task}\n")

        # Generate LIST.md for feature tracking and prioritization
        list_path = os.path.join(project_path, 'LIST.md')
        with open(list_path, 'w') as f:
            f.write("# Project Feature Tracking\n\n")

            # Implemented Features
            f.write("## Implemented Features\n")
            for feature in parsed_metadata.get('implemented_features', []):
                f.write(f"- [x] {feature}\n")

            # Planned Features
            f.write("\n## Planned Features\n")
            for feature in parsed_metadata.get('planned_features', []):
                f.write(f"- [ ] {feature}\n")

            # Priority Levels
            f.write("\n## Feature Priorities\n")
            priorities = parsed_metadata.get('feature_priorities', {})
            for priority, features in priorities.items():
                f.write(f"\n### {priority.capitalize()} Priority\n")
                for feature in features:
                    f.write(f"- {feature}\n")

            # Validation Notes
            f.write("\n## Validation Notes\n")
            validations = parsed_metadata.get('validation_notes', [])
            for note in validations:
                f.write(f"- {note}\n")

    def handle_generation_failure(self, error_message="AI generation failed. Please try again."):
        """
        Handle AI generation failure and update UI.
        """
        messagebox.showerror("AI Generation Failed", error_message)
        self.toggle_generation_ui(True)

    def toggle_generation_ui(self, enabled: bool):
        state = tk.NORMAL if enabled else tk.DISABLED
        self.prompt_entry.config(state=state)
        self.generate_btn.config(state=state)
        self.pause_btn.config(state=tk.DISABLED)
        self.stop_btn.config(state=tk.DISABLED)

    def populate_project_tree(self):
        try:
            self.project_tree.delete(*self.project_tree.get_children())
            self.current_project_files.clear()

            for root, dirs, files in os.walk(self.current_project):
                parent = self.project_tree.insert(
                    '',
                    'end',
                    text=os.path.basename(root),
                    values=(root,)
                )
                for file in files:
                    file_path = os.path.join(root, file)
                    file_id = self.project_tree.insert(
                        parent,
                        'end',
                        text=file,
                        values=(file_path,)
                    )
                    self.current_project_files[file_id] = file_path
        except Exception as e:
            logging.error(f"Error in populate_project_tree: {e}")

    def on_file_select(self, event):
        selected_item = self.project_tree.selection()
        if selected_item:
            file_path = self.project_tree.item(selected_item[0])['values'][0]
            if os.path.isfile(file_path):
                self.current_file_path = file_path
                with open(file_path, 'r') as f:
                    content = f.read()
                    self.file_editor.delete('1.0', tk.END)
                    self.file_editor.insert('1.0', content)
                    self.file_editor.edit_modified(False)

    def on_file_modified(self, event=None):
        pass

    def update_ai_plan(self, plan_text: str):
        self.ai_plan_listbox.delete(0, tk.END)
        steps = plan_text.split('\n')
        for step in steps:
            if step.strip():
                self.ai_plan_listbox.insert(tk.END, step)

    def run_tests(self):
        try:
            result = subprocess.run(
                ['pytest'],
                capture_output=True,
                text=True,
                cwd=self.current_project
            )
            self.log_output(result.stdout)
            if result.returncode == 0:
                self.log_output("Tests passed successfully!")
            else:
                self.log_output("Tests failed:\n" + result.stderr)
        except Exception as e:
            self.log_output(f"Test execution error: {e}")

    def log_output(self, message: str):
        self.output_console.config(state='normal')
        self.output_console.insert(tk.END, message + "\n")
        self.output_console.see(tk.END)
        self.output_console.config(state='disabled')
        logging.info(message)

    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s: %(message)s',
            handlers=[logging.FileHandler('project.log'), logging.StreamHandler()]
        )

    def show_about(self):
        messagebox.showinfo(
            "About Red-Green-Refactor IDE",
            "A comprehensive development environment for Test-Driven Development."
        )

    def pause_project(self):
        self.log_output("Project generation paused.")

    def stop_project(self):
        self.log_output("Project generation stopped.")
        self.prompt_entry.config(state=tk.NORMAL)
        self.generate_btn.config(state=tk.NORMAL)
        self.pause_btn.config(state=tk.DISABLED)
        self.stop_btn.config(state=tk.DISABLED)


if __name__ == '__main__':
    root = tk.Tk()
    app = RedGreenRefactorIDE(root)
    root.mainloop()

